{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify data with user input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/houda/.conda/envs/my_root/lib/python3.5/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score as cvs\n",
    "from pandas_confusion import ConfusionMatrix\n",
    "\n",
    "def getData(filename):\n",
    "    ''' Given a pkl filename, read it in as a pandas dataframe and return the transpose (features as column names)\n",
    "        of the dataframe. '''\n",
    "    data = pd.read_pickle(filename)\n",
    "    data = data.T\n",
    "    return data\n",
    "\n",
    "def removeAnomalies(data, parted):\n",
    "    ''' Given a pandas dataframe and a boolean value where zero means use all data and one means use the same\n",
    "        proportion of data labelled bought and not bought, return the dataframe without anomalies and with the \n",
    "        correct proportion for the data. '''\n",
    "    a = data.loc[data['Bought'] == 1]\n",
    "    goodBuys = a.loc[a['Average Time'] != 0]\n",
    "    notBought = data.loc[data['Bought'] == 0]\n",
    "    if parted:\n",
    "        data = [goodBuys, notBought[:goodBuys.shape[0] + 1]]\n",
    "    else: \n",
    "        data = [goodBuys, notBought]\n",
    "    data = pd.concat(data)\n",
    "    return data\n",
    "\n",
    "def convertZero(value):\n",
    "    ''' Given a value, convert the value if it is None to a string zero. Otherwise return the original value. '''\n",
    "    if value is None:\n",
    "        return '0'\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def convertTime(value):\n",
    "    ''' Convert the value from ms to seconds. '''\n",
    "    return value/1000\n",
    "    \n",
    "def stringToInt(data):\n",
    "    '''Given the pandas dataframe, convert all the strings into integers by categorizing the strings. Then return the \n",
    "        pandas dataframe with the converted strings and a list dat contains lists with which integer corresponds to \n",
    "        which string. '''\n",
    "    attributes = ['Country','Browser Teacher', 'OS Teacher', 'Browser Student', \n",
    "                  'OS Student', 'Mobile Teacher', 'Mobile Student']\n",
    "    # Holds the corresponding numbers of categories\n",
    "    data[['Average Time']] = data[['Average Time']].apply(convertTime)\n",
    "    indicesAttributes = []\n",
    "    for attribute in attributes:\n",
    "        data[attribute] = data[attribute].apply(convertZero) \n",
    "        if (attribute != 'Mobile Teacher') & (attribute != 'Mobile Student'):\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            data[attribute] = le.fit_transform(data[attribute])\n",
    "            indicesAttributes.append(list(le.classes_))\n",
    "    return (data,indicesAttributes)\n",
    "\n",
    "def splitData(data):\n",
    "    ''' Given a pandas dataframe, split the data into the labels, y and the features x. Then return x and y. '''\n",
    "    dataY = data['Bought']\n",
    "    dataX = data.ix[:,:-1]\n",
    "    dataX = dataX[['Amount of Students', 'Average Amount Students', 'Average Grade', \n",
    "         'Average Time', 'Country', 'Browser Teacher', 'OS Teacher',\n",
    "        'Browser Student', 'OS Student']]\n",
    "    y = np.asarray(dataY.values,dtype=\"int\")\n",
    "    x = dataX.values\n",
    "    return(x,y)\n",
    "\n",
    "def prepData(filename, parted):\n",
    "    ''' Given a pkl filename and a boolean value where zero means use all data and one means use the same\n",
    "        proportion of data labelled bought and not bought, return the features and labels without anomalies seperately\n",
    "        and the list that contains lists that contain which integer corresponds to which string. '''\n",
    "    data = getData(filename)\n",
    "    data = removeAnomalies(data, parted)\n",
    "    (data, indicesAttributes) = stringToInt(data)\n",
    "    (x,y) = splitData(data)\n",
    "    return (x, y, indicesAttributes)\n",
    "\n",
    "def applyML(x,y, algorithm):\n",
    "    ''' Given the features, labels and algorithm object, apply Machine Learning with that algorithm and return the \n",
    "        mean accuracy of the k-fold testing. '''\n",
    "    n_items = len(x)\n",
    "    kf = KFold(n_items, 8, shuffle = True, random_state = 4)\n",
    "    testVals = []\n",
    "    predYs = []\n",
    "    for train, test in kf:\n",
    "        testX = []\n",
    "        trainX = []\n",
    "        trainY = []\n",
    "        for tr in train:\n",
    "            trainX.append(x[tr])\n",
    "            trainY.append(y[tr])\n",
    "        for t in test:\n",
    "            testX.append(x[t])\n",
    "            testVals.append(y[t])\n",
    "        algorithm.fit(trainX, trainY)\n",
    "        predY = algorithm.predict(testX)\n",
    "        predYs.extend(predY)\n",
    "    good = 0\n",
    "    for j in range(len(predYs)):\n",
    "        if predYs[j] == testVals[j]:\n",
    "            good += 1\n",
    "    accuracy = good/len(predYs)\n",
    "    return (accuracy, testVals, predYs)\n",
    "\n",
    "def getAccuracy(MLObject, name, x, y):\n",
    "    ''' Given the algorithm object, name of the algorithm, the features and the labels, apply Machine Learning with the\n",
    "        algorithm, print a message about the accuracy and return the accuracy. '''\n",
    "    accuracy, testVals, predYs = applyML(x,y, MLObject)\n",
    "    accuracy = round(accuracy*100)\n",
    "    print(name, accuracy, '%.')\n",
    "    return (accuracy, testVals, predYs)\n",
    "\n",
    "def convertVals(testVals):\n",
    "    newVals = []\n",
    "    for val in testVals:\n",
    "        if val == 1:\n",
    "            newVals.append('Bought')\n",
    "        elif val == 0:\n",
    "            newVals.append('Not Bought')\n",
    "    return newVals\n",
    "\n",
    "def returnAllAccuracies(names, algorithms, x, y):\n",
    "    '''Given the list of algorithm names, the list of algorithm objects, the features and labels'''\n",
    "    accuracies = []\n",
    "    for i in range(len(algorithms)): \n",
    "        accuracy, testVals, predYs = getAccuracy(algorithms[i], names[i], x, y)\n",
    "        accuracies.append(accuracy)\n",
    "        testVals = convertVals(testVals)\n",
    "        predYs = convertVals(predYs)\n",
    "        confusion_matrix = ConfusionMatrix(testVals, predYs)\n",
    "        print(\"\\nConfusion matrix:\\n%s\" % confusion_matrix)\n",
    "        print(\"\\n\")\n",
    "    return accuracies\n",
    "\n",
    "def applyMLUserInput(xtrain, ytrain, xtest, algorithm):\n",
    "    algorithm.fit(xtrain, ytrain)\n",
    "    # 1 means buying\n",
    "    predY = algorithm.predict(xtest)\n",
    "    cols = ['Amount of Students', 'Average Amount Students', 'Average Grade', 'Average Time', 'Country', \n",
    "             'Browser Teacher', 'OS Teacher', 'Browser Student', 'OS Student', 'Prediction']\n",
    "    xtotal = []\n",
    "    for xNum in range(len(xtest)):\n",
    "        listX = list(xtest[xNum])\n",
    "        listX.append(predY[xNum])\n",
    "        xtotal.append(listX)\n",
    "    table = [[1 , 2], [3, 4]]\n",
    "    frame = pd.DataFrame(xtotal)\n",
    "    frame.columns = cols\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount of Students</th>\n",
       "      <th>Average Amount Students</th>\n",
       "      <th>Average Grade</th>\n",
       "      <th>Average Time</th>\n",
       "      <th>Country</th>\n",
       "      <th>Browser Teacher</th>\n",
       "      <th>OS Teacher</th>\n",
       "      <th>Browser Student</th>\n",
       "      <th>OS Student</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.513000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.274357</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.721311</td>\n",
       "      <td>27.513284</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>2.882353</td>\n",
       "      <td>37.413076</td>\n",
       "      <td>33</td>\n",
       "      <td>114</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>38.278318</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>46.055318</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.057143</td>\n",
       "      <td>55.227600</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.011682</td>\n",
       "      <td>35.908465</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>33.013125</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.178000</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>33.836600</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>37.852833</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>45.815812</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>38.641000</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>2.868000</td>\n",
       "      <td>107.141924</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.638350</td>\n",
       "      <td>64.672617</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>32.243406</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>169.580972</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.440945</td>\n",
       "      <td>37.108476</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>171.161125</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.953889</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.962963</td>\n",
       "      <td>97.497988</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.196429</td>\n",
       "      <td>52.788857</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>34.567800</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>27.548143</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>30.033300</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.104603</td>\n",
       "      <td>54.704259</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.956522</td>\n",
       "      <td>26.571652</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.646000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.764000</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>112.054711</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.930233</td>\n",
       "      <td>104.444884</td>\n",
       "      <td>33</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>13</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.827815</td>\n",
       "      <td>47.948722</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3304</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>71</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>13</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>114</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>114</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>44.959333</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>19</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>114</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>114</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3324 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Amount of Students  Average Amount Students  Average Grade  \\\n",
       "0                     12                 4.000000       0.000000   \n",
       "1                      2                 2.000000       1.000000   \n",
       "2                     18                18.000000       1.721311   \n",
       "3                     37                12.333333       2.882353   \n",
       "4                      1                 1.000000       2.818182   \n",
       "5                      2                 2.000000       2.636364   \n",
       "6                     15                15.000000       2.057143   \n",
       "7                     21                21.000000       2.011682   \n",
       "8                      2                 2.000000       2.250000   \n",
       "9                      1                 1.000000       3.000000   \n",
       "10                    14                14.000000       2.200000   \n",
       "11                     4                 4.000000       1.866667   \n",
       "12                     1                 1.000000       3.000000   \n",
       "13                    14                 4.666667       2.800000   \n",
       "14                    19                 6.333333       2.868000   \n",
       "15                    30                30.000000       2.638350   \n",
       "16                     3                 1.500000       2.843750   \n",
       "17                     2                 2.000000       2.750000   \n",
       "18                    25                25.000000       2.440945   \n",
       "19                     2                 2.000000       3.000000   \n",
       "20                     1                 1.000000       3.000000   \n",
       "21                     8                 8.000000       1.962963   \n",
       "22                     4                 4.000000       2.196429   \n",
       "23                     1                 1.000000       2.600000   \n",
       "24                     1                 1.000000       1.857143   \n",
       "25                     1                 1.000000       2.600000   \n",
       "26                    15                15.000000       2.104603   \n",
       "27                     1                 1.000000       2.956522   \n",
       "28                    20                20.000000       3.000000   \n",
       "29                     3                 3.000000       3.000000   \n",
       "...                  ...                      ...            ...   \n",
       "3294                   1                 1.000000       3.000000   \n",
       "3295                   1                 1.000000       2.930233   \n",
       "3296                   0                 0.000000       0.000000   \n",
       "3297                  13                13.000000       2.827815   \n",
       "3298                   0                 0.000000       0.000000   \n",
       "3299                   2                 2.000000       0.000000   \n",
       "3300                   0                 0.000000       0.000000   \n",
       "3301                   1                 1.000000       0.000000   \n",
       "3302                   0                 0.000000       0.000000   \n",
       "3303                   0                 0.000000       0.000000   \n",
       "3304                   0                 0.000000       0.000000   \n",
       "3305                  13                13.000000       0.000000   \n",
       "3306                   1                 1.000000       0.000000   \n",
       "3307                   0                 0.000000       0.000000   \n",
       "3308                   1                 1.000000       3.000000   \n",
       "3309                  19                19.000000       0.000000   \n",
       "3310                   9                 9.000000       0.000000   \n",
       "3311                   0                 0.000000       0.000000   \n",
       "3312                   0                 0.000000       0.000000   \n",
       "3313                   0                 0.000000       0.000000   \n",
       "3314                   0                 0.000000       0.000000   \n",
       "3315                   0                 0.000000       0.000000   \n",
       "3316                   0                 0.000000       0.000000   \n",
       "3317                   0                 0.000000       0.000000   \n",
       "3318                   0                 0.000000       0.000000   \n",
       "3319                   0                 0.000000       0.000000   \n",
       "3320                   0                 0.000000       0.000000   \n",
       "3321                   0                 0.000000       0.000000   \n",
       "3322                   0                 0.000000       0.000000   \n",
       "3323                   1                 1.000000       0.000000   \n",
       "\n",
       "      Average Time  Country  Browser Teacher  OS Teacher  Browser Student  \\\n",
       "0         8.513000        9                0           0                0   \n",
       "1         3.274357        9                0           0                0   \n",
       "2        27.513284       48                0           0                0   \n",
       "3        37.413076       33              114           7               43   \n",
       "4        38.278318       33                0           0                0   \n",
       "5        46.055318       33                0           0                0   \n",
       "6        55.227600       40                0           0               82   \n",
       "7        35.908465       33                0           0                0   \n",
       "8        33.013125       38                0           0                0   \n",
       "9        35.178000       16                0           0                0   \n",
       "10       33.836600       16                0           0                0   \n",
       "11       37.852833       22                0           0                0   \n",
       "12       45.815812       33                0           0                0   \n",
       "13       38.641000       33                0           0                0   \n",
       "14      107.141924       16                0           0                0   \n",
       "15       64.672617       33               29           7               17   \n",
       "16       32.243406       40                0           0                0   \n",
       "17      169.580972       33                0           0                0   \n",
       "18       37.108476       33                0           0                0   \n",
       "19      171.161125       36                0           0                0   \n",
       "20       33.953889       33                0           0                0   \n",
       "21       97.497988       16                0           0                0   \n",
       "22       52.788857       33                0           0                0   \n",
       "23       34.567800       48                0           0                0   \n",
       "24       27.548143       15                0           0                0   \n",
       "25       30.033300       33                0           0                0   \n",
       "26       54.704259       33                0           0                0   \n",
       "27       26.571652       33                0           0                0   \n",
       "28       76.646000       10                0           0                0   \n",
       "29       20.764000       31                0           0                0   \n",
       "...            ...      ...              ...         ...              ...   \n",
       "3294    112.054711       33               68           7               46   \n",
       "3295    104.444884       33              136           4               46   \n",
       "3296      0.000000       33              108           4                0   \n",
       "3297     47.948722       33               68           7               81   \n",
       "3298      0.000000       33               68           5                0   \n",
       "3299      0.000000       33               33           5                0   \n",
       "3300      0.000000       33              114           5                0   \n",
       "3301      0.000000       33               60          10                0   \n",
       "3302      0.000000        5               78           2                0   \n",
       "3303      0.000000       33              132           4                0   \n",
       "3304      0.000000       33               71           7                0   \n",
       "3305      0.000000       40              114           7                0   \n",
       "3306      0.000000       33               68           7                0   \n",
       "3307      0.000000       40              114           7                0   \n",
       "3308     44.959333       33               68           4               83   \n",
       "3309      0.000000       33               68           7                0   \n",
       "3310      0.000000       33               68           7               47   \n",
       "3311      0.000000       33               68           7                0   \n",
       "3312      0.000000       33               68           7                0   \n",
       "3313      0.000000       33               68           9                0   \n",
       "3314      0.000000       33               68           4                0   \n",
       "3315      0.000000       33               68           5                0   \n",
       "3316      0.000000        0               68           5                0   \n",
       "3317      0.000000       33               68           5                0   \n",
       "3318      0.000000       33               68           4                0   \n",
       "3319      0.000000       33              103           2                0   \n",
       "3320      0.000000       33              114           7                0   \n",
       "3321      0.000000       33               68           7                0   \n",
       "3322      0.000000       33              114           7                0   \n",
       "3323      0.000000       33              113           7                0   \n",
       "\n",
       "      OS Student  Prediction  \n",
       "0              0           1  \n",
       "1              0           1  \n",
       "2              0           1  \n",
       "3              7           1  \n",
       "4              0           1  \n",
       "5              0           1  \n",
       "6              4           1  \n",
       "7              0           1  \n",
       "8              0           1  \n",
       "9              0           1  \n",
       "10             0           1  \n",
       "11             0           1  \n",
       "12             0           1  \n",
       "13             0           1  \n",
       "14             0           1  \n",
       "15             1           1  \n",
       "16             0           1  \n",
       "17             0           1  \n",
       "18             0           1  \n",
       "19             0           1  \n",
       "20             0           1  \n",
       "21             0           1  \n",
       "22             0           1  \n",
       "23             0           1  \n",
       "24             0           1  \n",
       "25             0           1  \n",
       "26             0           1  \n",
       "27             0           1  \n",
       "28             0           1  \n",
       "29             0           1  \n",
       "...          ...         ...  \n",
       "3294           7           1  \n",
       "3295           4           1  \n",
       "3296           0           0  \n",
       "3297           4           1  \n",
       "3298           0           0  \n",
       "3299           0           0  \n",
       "3300           0           0  \n",
       "3301           0           0  \n",
       "3302           0           0  \n",
       "3303           0           0  \n",
       "3304           0           0  \n",
       "3305           0           0  \n",
       "3306           0           0  \n",
       "3307           0           0  \n",
       "3308           4           1  \n",
       "3309           0           0  \n",
       "3310           1           0  \n",
       "3311           0           0  \n",
       "3312           0           0  \n",
       "3313           0           0  \n",
       "3314           0           0  \n",
       "3315           0           0  \n",
       "3316           0           0  \n",
       "3317           0           0  \n",
       "3318           0           0  \n",
       "3319           0           0  \n",
       "3320           0           0  \n",
       "3321           0           0  \n",
       "3322           0           0  \n",
       "3323           0           0  \n",
       "\n",
       "[3324 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change files here as necessary\n",
    "trainFile = 'trialframe.pkl'\n",
    "testFile = 'trialframe.pkl'\n",
    "\n",
    "# Apply Machine Learning and show the dataframe with predictions\n",
    "algorithm = ExtraTreesClassifier(n_estimators=200, max_depth=None, min_samples_split=1, random_state=0)\n",
    "(xtrain, ytrain, indicesAttributesTrain) = prepData(testFile, 1)\n",
    "(xtest, ytest, indicesAttributesTest) = prepData(testFile, 0)\n",
    "newDataFrame = applyMLUserInput(xtrain, ytrain, xtest, algorithm)\n",
    "newDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Comparison of algorithms with confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NL-Algorithms when 50/50 data: \n",
      "\n",
      "Gaussian Naive Bayes:  70 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         154          78      232\n",
      "Not Bought      63         170      233\n",
      "__all__        217         248      465\n",
      "\n",
      "\n",
      "Support Vector Machine:  78 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         232           0      232\n",
      "Not Bought     100         133      233\n",
      "__all__        332         133      465\n",
      "\n",
      "\n",
      "Linear Vector Machine:  75 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         197          35      232\n",
      "Not Bought      79         154      233\n",
      "__all__        276         189      465\n",
      "\n",
      "\n",
      "Logistic Regression:  81 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         210          22      232\n",
      "Not Bought      65         168      233\n",
      "__all__        275         190      465\n",
      "\n",
      "\n",
      "SGD Classifier:  60 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         102         130      232\n",
      "Not Bought      58         175      233\n",
      "__all__        160         305      465\n",
      "\n",
      "\n",
      "Decision Tree Classifier:  78 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         180          52      232\n",
      "Not Bought      50         183      233\n",
      "__all__        230         235      465\n",
      "\n",
      "\n",
      "K-Nearest Neighbors:  77 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         197          35      232\n",
      "Not Bought      74         159      233\n",
      "__all__        271         194      465\n",
      "\n",
      "\n",
      "Random Forest:  81 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         190          42      232\n",
      "Not Bought      46         187      233\n",
      "__all__        236         229      465\n",
      "\n",
      "\n",
      "AdaBoost Classifier:  80 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         202          30      232\n",
      "Not Bought      64         169      233\n",
      "__all__        266         199      465\n",
      "\n",
      "\n",
      "Extra Trees Classifier:  85 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         210          22      232\n",
      "Not Bought      47         186      233\n",
      "__all__        257         208      465\n",
      "\n",
      "\n",
      "\n",
      "NL-Algorithms when complete data: \n",
      "\n",
      "Gaussian Naive Bayes:  72 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         192          40      232\n",
      "Not Bought     905        2187     3092\n",
      "__all__       1097        2227     3324\n",
      "\n",
      "\n",
      "Support Vector Machine:  93 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought          18         214      232\n",
      "Not Bought       3        3089     3092\n",
      "__all__         21        3303     3324\n",
      "\n",
      "\n",
      "Linear Vector Machine:  90 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought          79         153      232\n",
      "Not Bought     169        2923     3092\n",
      "__all__        248        3076     3324\n",
      "\n",
      "\n",
      "Logistic Regression:  94 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought          59         173      232\n",
      "Not Bought      31        3061     3092\n",
      "__all__         90        3234     3324\n",
      "\n",
      "\n",
      "SGD Classifier:  81 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought          43         189      232\n",
      "Not Bought     429        2663     3092\n",
      "__all__        472        2852     3324\n",
      "\n",
      "\n",
      "Decision Tree Classifier:  93 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought         123         109      232\n",
      "Not Bought     133        2959     3092\n",
      "__all__        256        3068     3324\n",
      "\n",
      "\n",
      "K-Nearest Neighbors:  93 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought           1         231      232\n",
      "Not Bought       0        3092     3092\n",
      "__all__          1        3323     3324\n",
      "\n",
      "\n",
      "Random Forest:  95 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought          92         140      232\n",
      "Not Bought      40        3052     3092\n",
      "__all__        132        3192     3324\n",
      "\n",
      "\n",
      "AdaBoost Classifier:  94 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought          98         134      232\n",
      "Not Bought      67        3025     3092\n",
      "__all__        165        3159     3324\n",
      "\n",
      "\n",
      "Extra Trees Classifier:  95 %.\n",
      "\n",
      "Confusion matrix:\n",
      "Predicted   Bought  Not Bought  __all__\n",
      "Actual                                 \n",
      "Bought          90         142      232\n",
      "Not Bought      34        3058     3092\n",
      "__all__        124        3200     3324\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 300\n",
    "# All tested algorithm objects\n",
    "algorithms = [GaussianNB(), svm.SVC(), svm.LinearSVC(), linear_model.LogisticRegression(), \n",
    "              linear_model.SGDClassifier(), DecisionTreeClassifier(max_depth=None, min_samples_split=1, random_state=0),\n",
    "              neighbors.KNeighborsClassifier(n_neighbors, weights='distance'), RandomForestClassifier(n_estimators=10),\n",
    "              AdaBoostClassifier(n_estimators=100), ExtraTreesClassifier(n_estimators=200,\n",
    "                                                                         max_depth=None, min_samples_split=1, \n",
    "                                                                         random_state=0)]\n",
    "namesAlgorithms = ['Gaussian Naive Bayes: ', 'Support Vector Machine: ', 'Linear Vector Machine: ', \n",
    "                   'Logistic Regression: ', 'SGD Classifier: ', 'Decision Tree Classifier: ', 'K-Nearest Neighbors: ', \n",
    "                   'Random Forest: ', 'AdaBoost Classifier: ', 'Extra Trees Classifier: ']\n",
    "\n",
    "# 50/50 difference\n",
    "print(\"NL-Algorithms when 50/50 data: \\n\")\n",
    "(x,y, indicesAttributes) = prepData('trialframe.pkl', 1)\n",
    "accuracies50 = returnAllAccuracies(namesAlgorithms, algorithms, x, y)\n",
    "\n",
    "# Complete data\n",
    "print(\"\\nNL-Algorithms when complete data: \\n\")\n",
    "(x,y, indicesAttributes) = prepData('trialframe.pkl', 0)\n",
    "accuraciesNormal = returnAllAccuracies(namesAlgorithms, algorithms, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Amount Classrooms\n",
      "0.408404178622\n",
      "\n",
      "2: Average Amount Students\n",
      "0.101625688699\n",
      "\n",
      "3: Referral\n",
      "0.0776313599271\n",
      "\n",
      "4: Average Time\n",
      "0.0756184517027\n",
      "\n",
      "5: Teacher/Parent\n",
      "0.0733884582583\n",
      "\n",
      "6: Amount of Students\n",
      "0.0679271710688\n",
      "\n",
      "7: Average Grade\n",
      "0.0676780057879\n",
      "\n",
      "8: Country\n",
      "0.0669589950326\n",
      "\n",
      "9: Average Tries\n",
      "0.0607676909018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "features = ['Teacher/Parent', 'Amount of Students', 'Amount Classrooms', 'Average Amount Students', 'Average Grade', \n",
    "         'Average Time', 'Average Tries', 'Referral', 'Country', 'Mobile Teacher', 'Browser Teacher', 'OS Teacher', \n",
    "         'Mobile Student', 'Browser Student', 'OS Student', 'Amount Logins Teacher', 'Amount Logins Students']\n",
    "\n",
    "# To see which features are the most important ones\n",
    "(x,y, indicesAttributes) = prepData('trialframe.pkl', 1)\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(x, y)\n",
    "feat = clf.feature_importances_ \n",
    "labeledResults = []\n",
    "for i in range(len(feat)): \n",
    "    labeledResults.append((i, feat[i]))\n",
    "\n",
    "# Sort on importance \n",
    "a = sorted(labeledResults, key = lambda x : x[1], reverse=True)\n",
    "count = 1\n",
    "for i in a:\n",
    "    print(str(count) + ': ' + features[i[0]])\n",
    "    print(str(i[1]) + '\\n')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Venn diagrams of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Divide buyers and non-buyers\n",
    "# Also needed for plots \n",
    "frame = getData('trialframe.pkl')\n",
    "frame = removeAnomalies(frame, 1)\n",
    "frame = convertZero(frame)\n",
    "frame, att = stringToInt(frame)\n",
    "newFrame = frame[['Amount of Students', 'Average Amount Students', 'Average Grade', \n",
    "                  'Average Time', 'Country', 'Browser Teacher', 'OS Teacher',\n",
    "                  'Browser Student', 'OS Student', 'Bought']]\n",
    "\n",
    "buyers = newFrame[newFrame.Bought == 1]\n",
    "nonBuyers = newFrame[newFrame.Bought == 0]\n",
    "(xnonBuyers, ynonBuyers) = splitData(nonBuyers)\n",
    "(xtotal, ytotal) = splitData(newFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: \n",
      "argentina 0.0%\n",
      "belgium 0.01%\n",
      "italy 0.0%\n",
      "morocco 0.01%\n",
      "\n",
      "\n",
      "Browser Teacher: \n",
      "Firefox 34.0 0.0%\n",
      "Firefox 39.0 0.0%\n",
      "Chrome 41.0.2272.118 0.0%\n",
      "Firefox 40.0 0.02%\n",
      "Chrome 44.0.2403.157 0.0%\n",
      "Safari 4.0 0.0%\n",
      "Chrome 45.0.2454.98 0.0%\n",
      "Safari 7.0 0.0%\n",
      "Chrome 46.0.2490.64 0.0%\n",
      "Safari 7.1.8 0.0%\n",
      "Safari 8.0.6 0.0%\n",
      "Safari 8.0.8 0.0%\n",
      "Chromium 45.0.2454.101 0.0%\n",
      "\n",
      "\n",
      "OS Teacher: \n",
      "Windows XP 0.01%\n",
      "Linux 0.0%\n",
      "Windows 8 0.01%\n",
      "\n",
      "\n",
      "Browser Student: \n",
      "Firefox 41.0 0.0%\n",
      "Firefox 42.0 0.01%\n",
      "Chrome 45.0.2454.93 0.02%\n",
      "Chrome 45.0.2454.98 0.01%\n",
      "Chrome 45.0.2454.99 0.0%\n",
      "Chrome 46.0.2490.71 0.0%\n",
      "\n",
      "\n",
      "OS Student: \n",
      "Windows Vista 0.0%\n",
      "Windows XP 0.0%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "\n",
    "categories = ['Country', 'Browser Teacher', 'OS Teacher', 'Browser Student', 'OS Student']\n",
    "\n",
    "# Make Venn diagrams and print percentages and categories of these diagrams\n",
    "for i in range(len(categories)):\n",
    "    plt.figure(i+1)\n",
    "    plt.title(\"Venn Diagram\" + categories[i])\n",
    "    set1 = set(buyers[categories[i]])\n",
    "    set2 = set(nonBuyers[categories[i]])\n",
    "    venn2([set1, set2],  set_labels = ('Buyers', 'Non-Buyers'))\n",
    "    print(categories[i] + \": \")\n",
    "    nonBuyersCat = set2.difference(set1.intersection(set2))\n",
    "    nonBuyersSet = list(nonBuyers[categories[i]])\n",
    "    for j in nonBuyersCat:\n",
    "        print(att[i][j] + ' ' + str(round(nonBuyersSet.count(j)/len(nonBuyersSet), 2)) + '%')\n",
    "    print(\"\\n\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 1, 0, 1, 1, 5,\n",
       "       1, 1, 0, 0, 0, 0, 6, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 2, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 3, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 4, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 2, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2,\n",
       "       1, 0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "# Clustering within the non buyers with meanshift\n",
    "meanshift = MeanShift()\n",
    "meanshift.fit(xnonBuyers)\n",
    "labels = meanshift.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 1,\n",
       "       2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0,\n",
       "       0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 2,\n",
       "       2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0,\n",
       "       0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
       "       0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2,\n",
       "       2, 0, 2], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Clustering within the non buyers with kMeans\n",
    "kmean = KMeans(n_clusters=3)\n",
    "kmean.fit_predict(xnonBuyers)\n",
    "labels = kmean.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  6,  1,\n",
       "        0,  0,  0,  0,  0,  0,  7,  1,  0,  0,  0,  0,  0,  0,  0,  0,  4,\n",
       "        0,  0,  0,  3,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0, 13,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  9,  0,  0,  0, 11,\n",
       "       12,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, 10,  2,  0,  0,  0,  0,  0,  0, 10,\n",
       "        0,  0,  1,  0,  0,  0,  0, 10,  0,  0,  3,  0,  0,  0,  0, 10,  0,\n",
       "        1,  0,  0,  0,  0, 10,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  1,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  8,\n",
       "        0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "        0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0, 10,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  1,  0,  0,  0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clustering in complete data with meanshift\n",
    "meanshift = MeanShift()\n",
    "meanshift.fit(xtotal)\n",
    "labels = meanshift.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clustering in complete data with kMeans\n",
    "kmean = KMeans(n_clusters=2)\n",
    "kmean.fit_predict(xtotal)\n",
    "labels = kmean.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/16.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a graph of the accuracies\n",
    "import plotly.plotly as py\n",
    "# Sign in with your information\n",
    "username = ''\n",
    "code = ''\n",
    "py.sign_in(username, code)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Data for 50/50 data\n",
    "trace1 = go.Bar(\n",
    "    x=namesAlgorithms,\n",
    "    y=accuracies50,\n",
    "    name='50/50 Data'\n",
    ") # Data for complete data\n",
    "trace2 = go.Bar(\n",
    "    x=namesAlgorithms,\n",
    "    y=accuraciesNormal,\n",
    "    name='All Data'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='grouped-barnew')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average values of the features: \n",
    "* Amount of Students\n",
    "* Average Amount Students \n",
    "* Average Grade\n",
    "* Average Tries\n",
    "* Average Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['Amount of Students', 'Average Amount Students', 'Average Grade', 'Average Time'] \n",
    "\n",
    "bmeans = []\n",
    "nmeans = []\n",
    "for feature in features:\n",
    "    bmeans.append(buyers[feature].mean())\n",
    "    nmeans.append(nonBuyers[feature].mean())\n",
    "    \n",
    "trace1 = go.Bar(x=features, y=bmeans, name='Buyers')\n",
    "trace2 = go.Bar(x=features, y=nmeans, name='Non-Buyers')\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(barmode='group')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common values of the features:\n",
    "* Country\n",
    "* Browser Teacher\n",
    "* OS Teacher\n",
    "* Browser Student\n",
    "* OS Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertNames(numbers, n):\n",
    "    ''' Given a list of categories in number form and the index of the category in the attributeslist,\n",
    "        return the list of categories in word form. '''\n",
    "    names = []\n",
    "    for num in numbers:\n",
    "        names.append(att[n][num])\n",
    "    return names\n",
    "\n",
    "def printGraph(n,buy):\n",
    "    ''' Make a graph of the corresponding input values that indicate a category and if it is bought or not. '''\n",
    "    if buy == 1:\n",
    "        values = mostcommonsb[n].reset_index().values\n",
    "    else:\n",
    "        values = mostcommonsn[n].reset_index().values\n",
    "    freq = values.T[1]\n",
    "    names = convertNames(values.T[0],n)\n",
    "    trace = go.Bar(x=names, y=freq)\n",
    "    data = [trace]\n",
    "    layout = go.Layout(barmode='group')\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get lists of most common values\n",
    "features2 = ['Country', 'Browser Teacher', 'OS Teacher', 'Browser Student', 'OS Student']\n",
    "\n",
    "n = 6\n",
    "mostcommonsb = []\n",
    "mostcommonsn = []\n",
    "for feature in features2:\n",
    "    mostcommonsb.append(buyers[feature].value_counts()[:n])\n",
    "    mostcommonsn.append(nonBuyers[feature].value_counts()[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common countries: non-buyers\n",
    "fig = printGraph(0,0)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common countries: buyers\n",
    "fig = printGraph(0,1)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most Common Browser Teacher: non-buyers\n",
    "fig = printGraph(1,0)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common Browser Teacher: non-buyers\n",
    "fig = printGraph(1,1)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most Common OS Teacher: non-buyers\n",
    "fig = printGraph(2,0)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most Common OS Teacher: buyers\n",
    "fig = printGraph(2,1)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common Browser Student: non-buyers\n",
    "fig = printGraph(3,0)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common Browser Students: buyers\n",
    "fig = printGraph(3,1)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common OS Students: non-buyers\n",
    "fig = printGraph(4,0)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~houda96/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common OS Student: buyers\n",
    "fig = printGraph(4,1)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
